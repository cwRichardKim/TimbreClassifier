{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy, scipy, matplotlib.pyplot as plt, pandas, librosa\n",
    "from IPython.display import Audio\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from os import path\n",
    "import sys\n",
    "import random\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num datapoints: 408\n",
      "update per 40\n",
      "0 adding classical_short_50/song0_8041.mp3 to classical\n",
      "1 adding classical_short_50/song9_5886.mp3 to classical\n",
      "2 adding classical_short_50/song5_3762.mp3 to classical\n",
      "3 adding classical_short_50/song4_2526.mp3 to classical\n",
      "4 adding classical_short_50/song2_3554.mp3 to classical\n",
      "5 adding classical_short_50/song4_890.mp3 to classical\n",
      "6 adding classical_short_50/song6_2044.mp3 to classical\n",
      "7 adding classical_short_50/song1_31.mp3 to classical\n",
      "8 adding classical_short_50/song3_270.mp3 to classical\n",
      "9 adding classical_short_50/song0_15537.mp3 to classical\n",
      "10 adding classical_short_50/song1_1924.mp3 to classical\n",
      "update per 40\n",
      "0 adding country_short_50/song7_4008.mp3 to country\n",
      "1 adding country_short_50/song6_1190.mp3 to country\n",
      "2 adding country_short_50/song5_457.mp3 to country\n",
      "3 adding country_short_50/song6_2941.mp3 to country\n",
      "4 adding country_short_50/song8_783.mp3 to country\n",
      "5 adding country_short_50/song6_50.mp3 to country\n",
      "6 adding country_short_50/song1_3389.mp3 to country\n",
      "7 adding country_short_50/song9_2589.mp3 to country\n",
      "8 adding country_short_50/song3_3035.mp3 to country\n",
      "9 adding country_short_50/song1_2410.mp3 to country\n",
      "10 adding country_short_50/song6_2012.mp3 to country\n",
      "number of classical slices: 408\n",
      "number of classical training slices: 371\n",
      "number of classical testing slices: 37\n",
      "number of country slices: 408\n",
      "number of country training slices: 371\n",
      "number of country testing slices: 37\n"
     ]
    }
   ],
   "source": [
    "slicelength = 50\n",
    "feature_power = 2\n",
    "data_proportion = .01\n",
    "\n",
    "classical_names = [f for f in os.listdir(\"./classical_short_%i/\" % slicelength)]\n",
    "country_names = [f for f in os.listdir(\"./country_short_%i/\" % slicelength)]\n",
    "\n",
    "num_datapoints = int(min(len(classical_names), len(country_names)) * data_proportion)\n",
    "print \"num datapoints: \" + str(num_datapoints)\n",
    "\n",
    "random.shuffle(classical_names)\n",
    "random.shuffle(country_names)\n",
    "classical_names = classical_names[0:num_datapoints]\n",
    "country_names = country_names[0:num_datapoints]\n",
    "\n",
    "def stft_array(names, kind):\n",
    "    update_per = len(names)/10\n",
    "    print \"update per %i\" % update_per\n",
    "    array = []\n",
    "    for i, x in enumerate(names):\n",
    "        song_path = '%s_short_%i/%s' % (kind, slicelength, x)\n",
    "        if i%update_per == 0:\n",
    "            sys.stdout.write(str(i/update_per) + \" \")\n",
    "            print \"adding \" + song_path + \" to \" + kind\n",
    "        csong_stft = librosa.stft(librosa.load(song_path)[0])\n",
    "        csong_log_stft = librosa.logamplitude(np.abs(csong_stft)**feature_power,ref_power=np.max)\n",
    "        csong_log_stft = [abs(item)/80.0 for sublist in csong_log_stft for item in sublist]\n",
    "        array.append(csong_log_stft)\n",
    "    return array\n",
    "    \n",
    "classical_train = stft_array(classical_names, 'classical')\n",
    "country_train = stft_array(country_names, 'country')\n",
    "\n",
    "test_classical = []\n",
    "test_country = []\n",
    "\n",
    "print \"number of classical slices: %i\" % len(classical_train)\n",
    "\n",
    "while len(test_classical) < len(classical_train) / 10:\n",
    "    r = randint(0, len(classical_train) - 1)\n",
    "    test_classical.append(classical_train[r])\n",
    "    del classical_train[r]\n",
    "    \n",
    "print \"number of classical training slices: %i\" % len(classical_train)\n",
    "print \"number of classical testing slices: %i\" % len(test_classical)\n",
    "\n",
    "print \"number of country slices: %i\" % len(country_train)\n",
    "while len(test_country) < len(country_train) / 10:\n",
    "    r = randint(0, len(country_train) - 1)\n",
    "    test_country.append(country_train[r])\n",
    "    del country_train[r]\n",
    "    \n",
    "print \"number of country training slices: %i\" % len(country_train)\n",
    "print \"number of country testing slices: %i\" % len(test_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All types check out\n",
      "training: 742\n",
      "testing: 74\n",
      "num features: 4100\n"
     ]
    }
   ],
   "source": [
    "testing_with_mnist = False\n",
    "\n",
    "if testing_with_mnist:\n",
    "    # testing to see if mnist will work here\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "    training = mnist.train.images\n",
    "    testing = mnist.test.images\n",
    "    training_validation_one_hot = mnist.train.labels\n",
    "    testing_validation_one_hot = mnist.test.labels\n",
    "else:\n",
    "    training = (numpy.array(classical_train + country_train)).astype(numpy.float32)\n",
    "    testing = (numpy.array(test_classical + test_country)).astype(numpy.float32)\n",
    "#     tr_len = len(temp_train)\n",
    "#     te_len = len(temp_testing)\n",
    "#     in_len = len(temp_train[0])\n",
    "\n",
    "#     training = [[temp_training[i][j] for j in range(in_len)] for i in range(tr_len)]\n",
    "#     testing = [[temp_testing[i][j] for j in range(in_len)] for i in range(te_len)]\n",
    "    \n",
    "#     for i in range(100):\n",
    "#         for j in range(10):\n",
    "#             print type(training[i][j])\n",
    "#             print training[i][j]\n",
    "#             print type(mnist.train.images[i][j])    \n",
    "#             print mnist.train.images[i][j]\n",
    "\n",
    "    classical_one_hot = numpy.array([0,1])\n",
    "    country_one_hot = numpy.array([1,0])\n",
    "    training_validation_one_hot = (numpy.array([classical_one_hot for x in classical_train] + [country_one_hot for x in country_train])).astype(numpy.float32)\n",
    "    testing_validation_one_hot = (numpy.array([classical_one_hot for x in test_classical] + [country_one_hot for x in test_country])).astype(numpy.float32)\n",
    "\n",
    "def type_check(array_types, num_types):\n",
    "    error_flag = False\n",
    "    for x in array_types:\n",
    "        if type(x) is numpy.ndarray:\n",
    "            print \"ARRAY TYPE ERROR\"\n",
    "            error_flag = True\n",
    "    for x in num_types:\n",
    "        if type(x) is numpy.float32:\n",
    "            print \"NUM TYPE ERROR\"\n",
    "            error_flag = True \n",
    "    if not error_flag:\n",
    "        print \"All types check out\"\n",
    "        \n",
    "array_types = [type(training), type(training[0]), type(training_validation_one_hot), type(training_validation_one_hot[0]),\n",
    "              type(testing), type(testing[0]), type(testing_validation_one_hot), type(testing_validation_one_hot[0])]\n",
    "num_types = [type(training[0][0]), type(training_validation_one_hot[0][0]), type(testing[0][0]), type(testing_validation_one_hot[0][0])]\n",
    "type_check(array_types, num_types)      \n",
    "\n",
    "if len(training)==len(training_validation_one_hot) and len(testing) == len(testing_validation_one_hot) and len(training[0])==len(testing[0]):\n",
    "    print \"training: \" + str(len(training))\n",
    "    print \"testing: \" + str(len(testing))\n",
    "    print \"num features: \" + str(len(training[0]))\n",
    "else:\n",
    "    print \"ERROR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# max_array = [max(x) for x in training]\n",
    "# print \"max val: \" + str(max(max_array))\n",
    "# min_array = [min(x) for x in training]\n",
    "# print \"min val: \" + str(min(min_array))\n",
    "# print \"peek: \" + str(training[10][0:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]]\n",
      "All types check out\n",
      "(array([ 1.,  0.], dtype=float32), array([ 0.,  1.], dtype=float32), array([ 1.,  0.], dtype=float32), array([ 0.,  1.], dtype=float32), array([ 1.,  0.], dtype=float32), array([ 1.,  0.], dtype=float32), array([ 1.,  0.], dtype=float32), array([ 1.,  0.], dtype=float32), array([ 0.,  1.], dtype=float32), array([ 0.,  1.], dtype=float32))\n",
      "All types check out\n",
      "(array([ 0.18023482,  0.24476567,  0.29893789, ...,  1.        ,\n",
      "        1.        ,  1.        ], dtype=float32), array([ 0.39146048,  0.32137173,  0.35087502, ...,  1.        ,\n",
      "        1.        ,  1.        ], dtype=float32), array([ 0.29891086,  0.35027358,  0.42402467, ...,  1.        ,\n",
      "        1.        ,  1.        ], dtype=float32), array([ 0.16271943,  0.21619442,  0.41105899, ...,  1.        ,\n",
      "        1.        ,  1.        ], dtype=float32), array([ 0.36539441,  0.39835516,  0.47473502, ...,  1.        ,\n",
      "        1.        ,  1.        ], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "def shuffle_array(xs, ys):\n",
    "    zipped = zip(xs,ys)\n",
    "    random.shuffle(zipped)\n",
    "    return zip(*zipped)\n",
    "print training_validation_one_hot[0:10]\n",
    "type_check(array_types, num_types)\n",
    "\n",
    "training, training_validation_one_hot = shuffle_array(training, training_validation_one_hot)\n",
    "testing, testing_validation_one_hot = shuffle_array(testing, testing_validation_one_hot)\n",
    "\n",
    "print training_validation_one_hot[0:10]\n",
    "type_check(array_types, num_types)\n",
    "\n",
    "print training[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num labels: 2\n",
      "num features: 4100\n"
     ]
    }
   ],
   "source": [
    "numLabels = len(training_validation_one_hot[0])\n",
    "featureSize = len(training[0])\n",
    "print \"num labels: \"+str(numLabels)\n",
    "print \"num features: \" + str(featureSize)\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, featureSize])\n",
    "W = tf.Variable(tf.zeros([featureSize, numLabels]))\n",
    "b = tf.Variable(tf.zeros([numLabels]))\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, numLabels])\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "\n",
    "# def weight_variable(shape):\n",
    "#     initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "#     return tf.Variable(initial)\n",
    "\n",
    "# def bias_variable(shape):\n",
    "#     initial = tf.constant(0.1, shape=shape)\n",
    "#     return tf.Variable(initial)\n",
    "\n",
    "# #convolution and pooling (may not need this)\n",
    "# def conv2d(x, W):\n",
    "#     return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "# def max_pool_2x2(x):\n",
    "#     return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "# #convolution layer\n",
    "# W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "# b_conv1 = bias_variable([32])\n",
    "\n",
    "# x_image = tf.reshape(x, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num iters: 247\n",
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 \n",
      "Training Complete\n",
      "0.513514\n",
      "[[  9.76127684e-01   2.38722786e-02]\n",
      " [  9.88279581e-01   1.17203891e-02]\n",
      " [  9.91206706e-01   8.79326090e-03]\n",
      " [  9.98010099e-01   1.98990945e-03]\n",
      " [  7.55190372e-01   2.44809657e-01]\n",
      " [  9.46132898e-01   5.38670905e-02]\n",
      " [  9.44687843e-01   5.53121753e-02]\n",
      " [  9.58514333e-01   4.14856263e-02]\n",
      " [  9.99992609e-01   7.41777103e-06]\n",
      " [  9.94619489e-01   5.38050383e-03]]\n",
      "(74, 2)\n",
      "(74, 4100)\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 1\n",
      "0 0\n",
      "0 0\n",
      "0 1\n"
     ]
    }
   ],
   "source": [
    "training_length = len(training)\n",
    "batch_size = 3\n",
    "num_iters = training_length / batch_size\n",
    "\n",
    "\n",
    "print \"num iters: \" + str(num_iters)\n",
    "\n",
    "for i in range(num_iters):\n",
    "    if i%(num_iters/100) == 0:\n",
    "        sys.stdout.write(str(i/(num_iters/100)) + \" \")\n",
    "    start = i*batch_size\n",
    "    end = (i+1)*batch_size\n",
    "    batch_xs = training[start:end]\n",
    "    batch_ys = training_validation_one_hot[start:end]\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "print \"\\nTraining Complete\"\n",
    "\n",
    "testing = numpy.asarray(testing)\n",
    "feed_dict = {x: testing}\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print (sess.run(accuracy, feed_dict={x: testing, y_: testing_validation_one_hot}))\n",
    "\n",
    "classification = sess.run(y, feed_dict)\n",
    "print classification[0:10]\n",
    "print classification.shape\n",
    "print testing.shape\n",
    "for i in range(10):\n",
    "    test = numpy.asarray(classification[i])\n",
    "    label = numpy.asarray(testing_validation_one_hot[i])\n",
    "    print str(test.argmax()) + \" \" + str(label.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.ops.variables.Variable object at 0x103fd5d50>\n"
     ]
    }
   ],
   "source": [
    "print W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
